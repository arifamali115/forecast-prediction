import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

from google.colab import files
uploaded = files.upload()  # This opens a file picker in the browser

# Load the dataset
file_path = "IoWT10minavg.csv"
df = pd.read_csv(file_path)

df.info(), df.head()

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from xgboost import XGBRegressor
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from tabulate import tabulate

# === Load Data ===
file_path = "IoWT10minavg.csv"  # Update if needed
df = pd.read_csv(file_path)
df['timestamp'] = pd.to_datetime(df['timestamp'], dayfirst=True)

# === Parameters ===
n_lags = 20
forecast_horizon = 12960
target_variables = ['ntu','orp','ph','tds','temp']

# === Evaluation Storage ===
results = []

# === Forecast Function ===
def predict_and_forecast(df, target_col):
    print(f"\n Processing: {target_col.upper()}")

    temp_df = df.copy()
    for i in range(1, n_lags + 1):
        temp_df[f'lag_{i}'] = temp_df[target_col].shift(i)
    temp_df = temp_df.dropna().reset_index(drop=True)

    feature_cols = [f'lag_{i}' for i in range(1, n_lags + 1)]
    X = temp_df[feature_cols]
    y = temp_df[target_col]

    # Split chronologically
    split_idx = int(len(X) * 0.7)
    X_train, X_test = X.iloc[:split_idx], X.iloc[split_idx:]
    y_train, y_test = y.iloc[:split_idx], y.iloc[split_idx:]

    # Model training
    model = XGBRegressor(objective='reg:squarederror', random_state=42)
    model.fit(X_train, y_train)

    # Prediction
    y_pred = model.predict(X_test)

    # Metrics
    mse = mean_squared_error(y_test, y_pred)
    rmse = np.sqrt(mse)
    mae = mean_absolute_error(y_test, y_pred)
    mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100
    r2 = r2_score(y_test, y_pred)
    results.append([target_col, round(mse, 4), round(rmse, 4), round(mae, 4), round(mape, 2), round(r2, 4)])

    # Forecast
    last_sequence = df[target_col].values[-n_lags:].tolist()
    future_preds = []

    for _ in range(forecast_horizon):
        X_input = pd.DataFrame([last_sequence[-n_lags:]], columns=feature_cols)
        next_val = model.predict(X_input)[0]
        future_preds.append(next_val)
        last_sequence.append(next_val)

    # === Plotting using sample index ===
    test_idx = range(len(y_test))
    forecast_idx = range(len(y_test), len(y_test) + forecast_horizon)

    # Plot 1: Actual vs Predicted
    plt.figure(figsize=(12, 5))
    plt.plot(test_idx, y_test.values, label='Actual', color='blue')
    plt.plot(test_idx, y_pred, label='Predicted', color='orange')
    plt.xlabel("Sample Index")
    plt.ylabel(target_col.upper())
    plt.title(f"{target_col.upper()} - Actual vs Predicted (Test Set)")
    plt.legend()
    plt.grid(True)
    plt.tight_layout()
    plt.show()

    # Plot 2: Forecast
    plt.figure(figsize=(14, 5))
    plt.plot(test_idx, y_pred, label='Predicted', color='blue')
    plt.plot(forecast_idx, future_preds, label='Forecast', linestyle='--', color='red')
    plt.xlabel("Sample Index")
    plt.ylabel(target_col.upper())
    plt.title(f"{target_col.upper()} Forecast - Next {forecast_horizon} Samples (90 Days)")
    plt.legend()
    plt.grid(True)
    plt.tight_layout()
    plt.show()

# === Run Forecast for Each Target ===
for target in target_variables:
    predict_and_forecast(df, target)

# === Print Evaluation Table ===
headers = ["Parameter", "MSE", "RMSE", "MAE", "MAPE (%)", "RÂ²"]
print("\n XGBoost Evaluation Results:\n")

