import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

from google.colab import files
uploaded = files.upload()  # This opens a file picker in the browser

# Load the dataset
file_path = "IoWT10minavg.csv"
df = pd.read_csv(file_path)

df.info(), df.head()

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from tabulate import tabulate

# === Load and Prepare Data ===
file_path = "IoWT10minavg.csv"  # Update if needed
df = pd.read_csv(file_path)

df['timestamp'] = pd.to_datetime(df['timestamp'], dayfirst=True)
df.sort_values('timestamp', inplace=True)
df.set_index('timestamp', inplace=True)

# Configuration
n_lags = 24
forecast_horizon = 12960  # 90 days = 12960 samples
parameters = ['ntu','orp','ph','tds','temp']

# === Helper Functions ===

# Create lag features
def create_lag_features(df, param, n_lags):
    for i in range(1, n_lags + 1):
        df[f'{param}_lag{i}'] = df[param].shift(i)
    df_lagged = df.dropna().copy()
    return df_lagged

# Forecasting function
def forecast_parameter(df, param, n_lags, forecast_horizon, model):
    df_lagged = create_lag_features(df, param, n_lags)

    feature_cols = [f'{param}_lag{i}' for i in range(1, n_lags + 1)]
    X = df_lagged[feature_cols]
    y = df_lagged[param]

    # No shuffle, maintain time series order
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle=False)

    model.fit(X_train, y_train)

    future_preds = []
    last_known_sequence = df_lagged.iloc[-1][feature_cols].tolist()

    for _ in range(forecast_horizon):
        X_input = pd.DataFrame([last_known_sequence[-n_lags:]], columns=X_train.columns)
        y_next = model.predict(X_input)[0]
        future_preds.append(y_next)
        last_known_sequence.append(y_next)

    return y_test.reset_index(drop=True), model.predict(X_test), future_preds

# === Main Forecasting and Plotting Loop ===

# Initialize model
model = RandomForestRegressor(n_estimators=100, random_state=42)

# Store results
results = []

for param in parameters:
    print(f"\n Forecasting for {param}...")

    y_test, y_pred, future_preds = forecast_parameter(df, param, n_lags, forecast_horizon, model)

    # Metrics
    mse = mean_squared_error(y_test, y_pred)
    rmse = np.sqrt(mse)
    mae = mean_absolute_error(y_test, y_pred)
    mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100
    r2 = r2_score(y_test, y_pred)
    results.append([param, round(mse, 4), round(rmse, 4), round(mae, 4), round(mape, 2), round(r2, 4)])

    # Sample indices
    test_idx = range(len(y_test))
    forecast_idx = range(len(y_test), len(y_test) + forecast_horizon)

    # === Plot: Actual vs Predicted ===
    plt.figure(figsize=(12, 5))
    plt.plot(test_idx, y_test.values, label='Actual', color='blue')
    plt.plot(test_idx, y_pred, label='Predicted', color='orange')
    plt.xlabel("Sample Index")
    plt.ylabel(param)
    plt.title(f"{param.upper()} - Actual vs Predicted (Test Set)")
    plt.legend()
    plt.grid(True)
    plt.tight_layout()
    plt.show()

    # === Plot: Forecast ===
    plt.figure(figsize=(14, 5))
    plt.plot(test_idx, y_pred, label='Predicted', color='blue')
    plt.plot(forecast_idx, future_preds, label='Forecast', linestyle='--', color='red')
    plt.xlabel("Sample Index")
    plt.ylabel(param)
    plt.title(f"{param.upper()} Forecast - Next 12960 Samples (90 Days)")
    plt.legend()
    plt.grid(True)
    plt.tight_layout()
    plt.show()

# === Print Evaluation Table ===
headers = ["Parameter", "MSE", "RMSE", "MAE", "MAPE (%)", "RÂ²"]
print("\n Random Forest Evaluation Results:\n")
print(tabulate(results, headers=headers, tablefmt="github"))

# ðŸ§¾ Print performance results
print("\n Random Forest Evaluation Results:")
pd.DataFrame(results).T
